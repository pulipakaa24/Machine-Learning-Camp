# -*- coding: utf-8 -*-
"""Divorce

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1riV4l907GhiVi2C3TSwessHux5JAQqef
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split as tts
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

dataset = pd.read_csv('divorce.csv')
x = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values
# xtrain = x[:135, :]
# xtest = x[135:, :]
# ytrain = y[:135]
# ytest = y[135:]
xtrain, xtest, ytrain, ytest = tts(x, y, test_size = 0.2, random_state = 0)

c = DecisionTreeClassifier(random_state=0)
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

cl = SVC(kernel='rbf', random_state=0)
cl.fit(xtrain, ytrain)
y1pred = cl.predict(xtest)
print(accuracy_score(ytest, y1pred))

c = LogisticRegression(random_state=0)
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = KNeighborsClassifier(n_neighbors=5)
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = GaussianNB()
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = RandomForestClassifier(random_state=0)
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))