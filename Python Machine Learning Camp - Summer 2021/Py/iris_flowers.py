# -*- coding: utf-8 -*-
"""Iris Flowers

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11nWqzDqy5gNQdQlKVlRMPp-RjVczCCp6
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split as tts
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import scipy.cluster.hierarchy as sch
from sklearn.cluster import AgglomerativeClustering
from sklearn.cluster import KMeans

db = pd.read_csv('Iris.csv')
x = db.iloc[:, 1:-1].values
y = db.iloc[:, -1:].values
xtrain, xtest, ytrain, ytest = tts(x, y, test_size = 0.25, random_state=0)
print(xtrain)

c = DecisionTreeClassifier()
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = RandomForestClassifier()
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = KNeighborsClassifier(n_neighbors=3)
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

c = SVC(kernel='rbf')
c.fit(xtrain, ytrain)
ypred = c.predict(xtest)
print(accuracy_score(ytest, ypred))

dend = sch.dendrogram(sch.linkage(x, method='ward'))
plt.show()

hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')
yhc = hc.fit_predict(x)
plt.scatter(x[yhc == 0, 0], x[yhc == 0, 1], s=100, c='red', label='Cluster1')
plt.scatter(x[yhc == 1, 0], x[yhc == 1, 1], s=100, c='blue', label = 'Cluster2')
plt.scatter(x[yhc == 2, 0], x[yhc == 2, 1], s=100, c='green', label='Cluster3')
plt.legend()
plt.show()

WCSS = []
for i in range(1, 11):
  km = KMeans(n_clusters=i, init='k-means++', random_state=0)
  km.fit(x)
  WCSS.append(km.inertia_)

plt.plot(range(1, 11), WCSS)

km = KMeans(n_clusters=3, init='k-means++', random_state=0)
ykm = km.fit_predict(x)
plt.scatter(x[ykm == 0, 0], x[ykm == 0, 1], s=100, c='red', label='Cluster1')
plt.scatter(x[ykm == 1, 0], x[ykm == 1, 1], s=100, c='blue', label = 'Cluster2')
plt.scatter(x[ykm == 2, 0], x[ykm == 2, 1], s=100, c='green', label='Cluster3')
plt.legend()
plt.show()